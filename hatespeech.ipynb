{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For text preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# For BERT\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFAlbertForSequenceClassification, AlbertTokenizer, AlbertModel\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_id         0\n",
      "annotator_id    0\n",
      "label           0\n",
      "target          1\n",
      "post_tokens     0\n",
      "dtype: int64\n",
      "normal        515\n",
      "hatespeech    296\n",
      "offensive     189\n",
      "Name: label, dtype: int64\n",
      "                       post_id  annotator_id   label target  \\\n",
      "0  1179055004553900032_twitter             1  normal   None   \n",
      "1  1179055004553900032_twitter             2  normal   None   \n",
      "2  1179055004553900032_twitter             3  normal   None   \n",
      "3  1179063826874032128_twitter             1  normal   None   \n",
      "4  1179063826874032128_twitter             2  normal   None   \n",
      "\n",
      "                                         post_tokens  \n",
      "0  i dont think im getting my baby them white 9 h...  \n",
      "1  i dont think im getting my baby them white 9 h...  \n",
      "2  i dont think im getting my baby them white 9 h...  \n",
      "3  we cannot continue calling ourselves feminists...  \n",
      "4  we cannot continue calling ourselves feminists...  \n"
     ]
    }
   ],
   "source": [
    "# Load your dataset (ensure it's in the correct format: CSV with 'text' and 'label' columns)\n",
    "df = pd.read_csv('./data/hateXplain.csv')\n",
    "df = df[0:1000]\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic exploration of the dataset\n",
    "print(df['label'].value_counts())\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['post_tokens'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# For traditional models: use TF-IDF to convert text into feature vectors\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to 5000 features for performance\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.81        93\n",
      "           1       0.79      0.72      0.75        67\n",
      "           2       0.92      0.30      0.45        40\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.81      0.66      0.67       200\n",
      "weighted avg       0.78      0.74      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_predictions = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(classification_report(y_test, nb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        93\n",
      "           1       0.76      0.82      0.79        67\n",
      "           2       0.74      0.65      0.69        40\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.79      0.77      0.78       200\n",
      "weighted avg       0.80      0.80      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Support Vector Machine model\n",
    "svm_model = SVC(kernel='linear')  # Linear kernel is commonly used for text classification\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_predictions = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(classification_report(y_test, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "# # Map the labels (assuming 'normal' -> 0, 'hatespeech' -> 1, 'offensive' -> 2)\n",
    "# label_mapping = {'normal': 0, 'hatespeech': 1, 'offensive': 2}\n",
    "# df['label'] = df['label'].map(label_mapping)\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df['post_tokens'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v1')\n",
    "\n",
    "# Tokenize the text data for BERT\n",
    "def tokenize_text(text, max_length=128):\n",
    "    return tokenizer(text.tolist(), \n",
    "                     padding='max_length', \n",
    "                     truncation=True, \n",
    "                     max_length=max_length, \n",
    "                     return_tensors='tf')\n",
    "\n",
    "# Tokenize the training and testing sets\n",
    "train_encodings = tokenize_text(X_train)\n",
    "test_encodings = tokenize_text(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFAlbertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train.values)).batch(128)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test.values)).batch(128)\n",
    "\n",
    "\n",
    "from transformers import TFBertForSequenceClassification, create_optimizer\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification (with 3 output labels)\n",
    "model = TFAlbertForSequenceClassification.from_pretrained('albert-base-v1', num_labels=3)\n",
    "\n",
    "# Number of training steps\n",
    "batch_size = 128\n",
    "num_train_steps = len(X_train) // batch_size * 1  # Assuming 3 epochs\n",
    "\n",
    "# Create the AdamW optimizer\n",
    "optimizer, lr_schedule = create_optimizer(init_lr=2e-5, num_train_steps=num_train_steps, num_warmup_steps=0)\n",
    "\n",
    "# Compile the model using AdamW optimizer\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1437s 203s/step - loss: 1.1386 - accuracy: 0.3325 - val_loss: 1.0493 - val_accuracy: 0.4750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x248120dd660>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the BERT model\n",
    "model.fit(train_dataset, \n",
    "          validation_data=test_dataset, \n",
    "          epochs=1)  # You can adjust the number of epochs as needed\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 36s 14s/step - loss: 1.0493 - accuracy: 0.4750\n",
      "Test Accuracy: 0.4750\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the BERT model on the test dataset\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.745\n",
      "SVM Accuracy: 0.8\n",
      "BERT Test Accuracy: 0.4749999940395355\n"
     ]
    }
   ],
   "source": [
    "# Summary of all model performances\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"BERT Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
