{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For text preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# For BERT\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFAlbertForSequenceClassification, AlbertTokenizer, AlbertModel, DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24783\n",
      "Unnamed: 0            0\n",
      "count                 0\n",
      "hate_speech           0\n",
      "offensive_language    0\n",
      "neither               0\n",
      "class                 0\n",
      "tweet                 0\n",
      "dtype: int64\n",
      "1    19190\n",
      "2     4163\n",
      "0     1430\n",
      "Name: class, dtype: int64\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "# Load your dataset (ensure it's in the correct format: CSV with 'text' and 'label' columns)\n",
    "df = pd.read_csv('./data/labeled_data.csv')\n",
    "\n",
    "print(len(df))\n",
    "# df = df[0:15000]\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic exploration of the dataset\n",
    "print(df['class'].value_counts())\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Content  Label\n",
      "0      !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
      "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
      "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
      "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
      "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1\n",
      "...                                                  ...    ...\n",
      "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...      1\n",
      "24779  you've gone and broke the wrong heart baby, an...      2\n",
      "24780  young buck wanna eat!!.. dat nigguh like I ain...      1\n",
      "24781              youu got wild bitches tellin you lies      1\n",
      "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...      2\n",
      "\n",
      "[24783 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and testing sets (80-20 split)\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'tweet': 'Content',\n",
    "    'class': 'Label'\n",
    "})\n",
    "\n",
    "df = df[['Content', 'Label']]\n",
    "\n",
    "print(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Content'], df['Label'], test_size=0.2, random_state=42, stratify=df['Label'])\n",
    "\n",
    "# For traditional models: use TF-IDF to convert text into feature vectors\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to 5000 features for performance\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8269114383699818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01       286\n",
      "           1       0.82      0.99      0.90      3838\n",
      "           2       0.89      0.34      0.49       833\n",
      "\n",
      "    accuracy                           0.83      4957\n",
      "   macro avg       0.90      0.45      0.47      4957\n",
      "weighted avg       0.84      0.83      0.78      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Multinomial Naive Bayes model\n",
    "nb_model_mn = MultinomialNB()\n",
    "nb_model_mn.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_predictions_mn = nb_model_mn.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions_mn))\n",
    "print(classification_report(y_test, nb_predictions_mn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9074036715755497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.13      0.21       286\n",
      "           1       0.92      0.97      0.94      3838\n",
      "           2       0.85      0.91      0.88       833\n",
      "\n",
      "    accuracy                           0.91      4957\n",
      "   macro avg       0.80      0.67      0.68      4957\n",
      "weighted avg       0.89      0.91      0.89      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Support Vector Machine model\n",
    "svm_model = SVC(kernel='linear')  # Linear kernel is commonly used for text classification\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_predictions = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(classification_report(y_test, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the text data for BERT\n",
    "def tokenize_text(text, max_length=128):\n",
    "    return tokenizer(text.tolist(), \n",
    "                     padding=True, \n",
    "                     truncation=True, \n",
    "                     max_length=max_length, \n",
    "                     return_tensors='tf')\n",
    "\n",
    "# Tokenize the training and testing sets\n",
    "train_encodings = tokenize_text(X_train)\n",
    "test_encodings = tokenize_text(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train.values)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test.values)).batch(32)\n",
    "\n",
    "\n",
    "from transformers import TFBertForSequenceClassification, create_optimizer\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification (with 3 output labels)\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n",
    "\n",
    "# Number of training steps\n",
    "batch_size = 32\n",
    "num_train_steps = len(X_train) // batch_size * 1  # Assuming 3 epochs\n",
    "\n",
    "num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "# Create the AdamW optimizer\n",
    "optimizer, lr_schedule = create_optimizer(init_lr=2e-5, num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "# Compile the model using AdamW optimizer\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "620/620 [==============================] - 9393s 15s/step - loss: 0.3456 - accuracy: 0.8795 - val_loss: 0.2419 - val_accuracy: 0.9163\n",
      "Epoch 2/3\n",
      "620/620 [==============================] - 9762s 16s/step - loss: 0.2310 - accuracy: 0.9194 - val_loss: 0.2419 - val_accuracy: 0.9163\n",
      "Epoch 3/3\n",
      "620/620 [==============================] - 10390s 17s/step - loss: 0.2290 - accuracy: 0.9203 - val_loss: 0.2419 - val_accuracy: 0.9163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x1a3d1721810>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define a custom callback to calculate F1-score after each epoch\n",
    "# class F1ScoreCallback(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self, validation_data):\n",
    "#         super(F1ScoreCallback, self).__init__()\n",
    "#         self.validation_data = validation_data\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         val_data = self.validation_data\n",
    "#         val_x = val_data[0]\n",
    "#         val_y = val_data[1]\n",
    "#         predictions = np.argmax(self.model.predict(val_x), axis=-1)\n",
    "#         f1 = f1_score(val_y, predictions, average='weighted')  # You can change the averaging method if needed\n",
    "#         print(f\"F1-Score for epoch {epoch + 1}: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# Train the BERT model\n",
    "# f1_callback = F1ScoreCallback(validation_data=(test_encodings, y_test.values))\n",
    "model.fit(train_dataset, \n",
    "          validation_data=test_dataset, \n",
    "          epochs=3)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 711s 5s/step - loss: 0.2419 - accuracy: 0.9163\n",
      "Test Accuracy: 0.9163\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the BERT model on the test dataset\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8269114383699818\n",
      "SVM Accuracy: 0.9074036715755497\n",
      "DistilBERT Test Accuracy: 0.9162800312042236\n"
     ]
    }
   ],
   "source": [
    "# Summary of all model performances\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions_mn))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"DistilBERT Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 46s 1s/step\n",
      "Ensemble Accuracy: 0.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you already have predictions or probability outputs for each model\n",
    "# Naive Bayes and SVM typically need probability outputs for soft voting, so ensure they're configured for that\n",
    "nb_probas = nb_model_mn.predict_proba(X_test_tfidf)    # Naive Bayes probabilities\n",
    "svm_probas = svm_model.decision_function(X_test_tfidf)  # SVM decision function (convert to probabilities if needed)\n",
    "bert_probas = model.predict(test_dataset).logits    # BERT raw logits\n",
    "\n",
    "# Convert BERT logits to probabilities\n",
    "bert_probas = tf.nn.softmax(bert_probas, axis=1).numpy()\n",
    "\n",
    "# Average the probabilities for each class\n",
    "ensemble_probas = (nb_probas + svm_probas + bert_probas) / 3  # Equal weighting\n",
    "\n",
    "# Choose the class with the highest average probability\n",
    "ensemble_predictions = np.argmax(ensemble_probas, axis=1)\n",
    "\n",
    "# Evaluate ensemble performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
